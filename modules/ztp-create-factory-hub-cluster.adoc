// Module included in the following assemblies:
//
// * scalability_and_performance/ztp-factory-install-clusters.adoc
:_content-type: CONCEPT
[id="preparing-the-factory-install-environment_{context}"]
= Preparing the factory install environment

.Prerequisites
Before you can provision edge clusters at scale, you must meet the following prerequisites:

=== Base

* Deploy the {product-title} cluster with three control plane nodes following the guidance in the section "Deploying installer-provisioned clusters on bare metal". Alternatively you can use the technology preview Assisted Installer from link:https://cloud.redhat.com/[cloud.redhat.com] to create the cluster.
** All Cluster Operators are available.
** Cluster is reachable using a `KUBECONFIG` file.
** The API, API-INT and ingress should be deployed on the DHCP external Network (factory network).

=== Storage

* Storage can be provided by installing the Local Storage Operator and by using local volumes. However it is recommended to use OpenShift Data Foundation. Deploy the OpenShift Data Foundation following the guidance in link:https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.9/html/deploying_openshift_data_foundation_using_bare_metal_infrastructure/index[Deploying OpenShift Data Foundation using bare metal infrastructure].

** Create storage classes and persistent volumes with at least 200Gb of storage (NVMe or SSD) for:

    *** 2 persistent volumes for Assisted Installer.
    *** 1 for the hub internal registry that is for the mirror of the images. At least 200Gb is required on the hub, more may be required if ODF is installed.
    *** 1 persistent volume for HTTPD that hosts the Red Hat Enterprise Linux CoreOS (RHCOS) images.
    *** 1 for zero touch provisioning factory worflows (ZTPFW).
    *** 1 for Advanced Cluster Manager (ACM)

=== Networking

The hub cluster requires internet connectivity and should be installed on a private network with customer configured DNS and DHCP services. DNS needs configured for the API on the ingress of the hub to reach some routes on the hub cluster. DNS entries needs configured for the number of edge clusters you intend to deploy in parallel.

You need enough DHCP addresses to host the number of edge clusters you intend to deploy. Each {product-title} node in the cluster must have access to an NTP server. {product-title} nodes use NTP to synchronize their clocks. For example, cluster nodes use SSL certificates that require validation, which might fail if the date and time between the nodes are not in sync.

Specific requirements are:

* DNS entries need to be configured and resolvable from the internal and external network, with DNS on the DHCP external network.
* Hub.
** `api.<hub-domain>.<domain> and api-int.<hub-domain>.<domain>` entries to the same IP address.
** ingress (`*.apps.<hub-domain>.<net-domain>`).

* Edge
** `api.<spoke-domain>.<net-domain>` and `api-int.<spoke-domain>.<net-domain>` entries to the same IP address.
** ingress (`*.apps.<spoke-domain>.<net-domain>`).

* External DHCP with some free IPs on the factory network to provide access to the edge cluster by using the external network interface.

* Every edge cluster needs at least 6 IPs from this external network (without the broadcast and network IP).
** 1 per node.
** 1 for API.
** 1 for API-INT.
** 1 for the Ingress entry (`*.apps.<spoke-domain>.<net-domain>`).
