[id="telco-core-deployment-planning"]
= Deployment planning

*Worker Nodes and MachineConfigPools*

Worker nodes in Telco core clusters can be subdivided into different node groups based on customer planning parameters through the use of MachineConfigPools (MCPs).
Careful deployment planning using MCPs is crucial to minimize deployment and upgrade time and, more importantly, to minimize interruption of telco-grade services during cluster upgrades.

*Description*

Telco core clusters can use MachineConfigPools (MCPs) to split worker nodes into additional separate roles, for example, due to different hardware profiles.
This allows custom tuning for each role and also plays a critical function in speeding up a telco core cluster deployment or upgrade.
More importantly, multiple MCPs can be used to properly plan cluster upgrades across one or multiple maintenance windows.
This is crucial because telco-grade services might otherwise be affected if careful planning is not considered.

During cluster upgrades, MCPs can be paused while the control plane is upgraded (see https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/updating_clusters/performing-a-cluster-update#update-using-custom-machine-config-pools[canary upgrade]).
This ensures that worker nodes are not rebooted and running workloads remain unaffected until the MCP is unpaused.
Using careful MCP planning, you can control the timing and order of which set of nodes are upgraded at any time.
For more information on how to use MCPs to plan telco upgrades, see https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/edge_computing/day-2-operations-for-telco-core-cnf-clusters#telco-update-applying-mcp-labels-to-nodes-before-the-update_ocp-update-prep[Applying MachineConfigPool labels to nodes before the update].

_Engineering Considerations before initial deployment_

### Engineering Considerations Before Initial Deployment

Before beginning the initial deployment, keep the following engineering considerations in mind regarding MCPs:

**PerformanceProfile and Tuned profile association:**
When using PerformanceProfiles, remember that each Machine Config Pool (MCP) must be linked to exactly one PerformanceProfile or Tuned profile definition.
Consequently, even if the desired configuration is identical for multiple MCPs, each MCP still requires its own dedicated PerformanceProfile definition.

**Planning your MCP labeling strategy:**
Plan your MCP labeling with an appropriate strategy to split your worker nodes depending on parameters such as:

* The worker node type, identifying a group of nodes with equivalent hardware profile for example workers for control plane Network Functions (NFs) and workers for user data plane NFs.
* The number of worker nodes per worker node type.
* The minimum number of MCPs required for an equivalent hardware profile is 1, but could be larger for larger clusters.
  For example, you may design for more MCPs per hardware profile to support a more granular upgrade where a smaller percentage of the cluster capacity is affected with each step.
* The strategy for performing updates on nodes within an MCP is shaped by upgrade requirements and the chosen `maxUnavailable` value:
** Number of maintenance windows allowed.
** Duration of a maintenance window.
** Total number of worker nodes.
** Desired `maxUnavailable` (number of nodes updated concurrently) for the MCP.
* CNF requirements for worker nodes, in terms of:
** Minimum availability per Pod required during an upgrade, configured with a Pod Disruption Budget (PDB). link:https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/nodes/working-with-pods#nodes-pods-pod-distruption-about_nodes-pods-configuring[PDBs] are crucial to maintain Telco Service level Agreements (SLAs) during upgrades.
** Minimum true high availability required per Pod, such that each replica runs on separate hardware.
** Pod affinity and anti-affinity link:https://docs.redhat.com/en/documentation/openshift_container_platform/4.18/html/nodes/controlling-pod-placement-onto-nodes-scheduling#nodes-scheduler-pod-affinity[rules]
* Duration and number of upgrade maintenance windows during which telco-grade services might be affected.

